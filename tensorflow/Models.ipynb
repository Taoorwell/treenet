{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow.keras.models import *\n",
    "# from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, BatchNormalization, Activation, add, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v2.version' from 'C:\\\\OSGEO4~1\\\\apps\\\\Python37\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\version\\\\__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "# image_path = u'../../tiles/'\n",
    "# mask_path = u'../../masks/'\n",
    "# images = [image_path + i for i in os.listdir(image_path)]\n",
    "# masks = [mask_path + i for i in os.listdir(mask_path)]\n",
    "path = u'../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    images_path = glob(os.path.join(path, \"tiles/*\"))\n",
    "    masks_path = glob(os.path.join(path, \"masks/*\"))\n",
    "    return images_path, masks_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(path, patch_size, num):\n",
    "#     images_path = glob(os.path.join(path, \"tiles/*\"))\n",
    "#     masks_path = glob(os.path.join(path, \"masks/*\"))\n",
    "#     images, masks, locations = [], [], []\n",
    "#     for image_path, mask_path in zip(images_path, masks_path):\n",
    "#         for i in range(num):\n",
    "#             location = np.random.randint(patch_size/2 - 1, 999 - patch_size/2, (2,))\n",
    "#             images.append(image_path)\n",
    "#             masks.append(mask_path)\n",
    "#             locations.append(location)\n",
    "#     return images, masks, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, masks, locations = load_data(path, patch_size=256, num=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raster(raster_path):\n",
    "    ds = gdal.Open(raster_path)\n",
    "    data = np.empty((ds.RasterYSize, ds.RasterXSize, ds.RasterCount))\n",
    "    for b in range(1, ds.RasterCount + 1):\n",
    "        band = ds.GetRasterBand(b).ReadAsArray()\n",
    "        data[:, :, b-1] = band\n",
    "    if data.shape[-1] > 1:\n",
    "        data = norma_data(data, norma_methods='min-max')   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norma_data(data, norma_methods=\"z-score\"):\n",
    "    arr = np.empty(data.shape)\n",
    "    for i in range(data.shape[-1]):\n",
    "        array = data.transpose(2, 0, 1)[i, :, :]\n",
    "        mins, maxs, mean, std= np.percentile(array, 1), np.percentile(array, 99), np.mean(array), np.std(array)\n",
    "        if norma_methods == \"z-score\":\n",
    "            new_array = (array-mean)/std\n",
    "        else:\n",
    "            new_array = np.clip(2*(array-mins)/(maxs-mins), 0, 1)\n",
    "        arr[:, :, i] = new_array\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path, masks_path = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = tf.data.Dataset.from_tensor_slices((images_path, masks_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.string)>\n"
     ]
    }
   ],
   "source": [
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pare_fun(x, y):\n",
    "    def f(x, y):\n",
    "        x = x.decode()\n",
    "        y = y.decode()\n",
    "    \n",
    "        x = get_raster(x)\n",
    "        y = get_raster(y)\n",
    "        return x, y\n",
    "    \n",
    "    image, mask = tf.numpy_function(f, [x, y], [tf.double, tf.double])\n",
    "    image.set_shape([1000, 1000, 7])\n",
    "    mask.set_shape([1000, 1000, 1])\n",
    "    return image, mask\n",
    "\n",
    "# def pare_fun(x, y, z):\n",
    "#     patch_size = 256\n",
    "#     def f(x, y, z):\n",
    "#         x = x.decode()\n",
    "#         y = y.decode()\n",
    "    \n",
    "#         x = get_raster(x)\n",
    "#         y = get_raster(y)\n",
    "        \n",
    "#         h, w = z[0], z[1]\n",
    "#         d1 = int(patch_size/2 - 1)\n",
    "#         d2 = int(patch_size - d1)\n",
    "        \n",
    "#         x = x[h-d1: h+d2, w-d1: w+d2, :]\n",
    "#         y = y[h-d1: h+d2, w-d1: w+d2]  \n",
    "#         return x, y, z\n",
    "    \n",
    "#     image, mask, location = tf.numpy_function(f, [x, y, z], [tf.double, tf.double, tf.int32])\n",
    "#     image.set_shape([patch_size, patch_size, 7])\n",
    "#     mask.set_shape([patch_size, patch_size, 1])\n",
    "#     return image, mask, location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(datasets.map(pare_fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator(ds, width, num):\n",
    "    images_patch = np.zeros((len(ds)*num, width, width, 7))\n",
    "    masks_patch = np.zeros((len(ds)*num, width, width, 1))\n",
    "    j = 0\n",
    "    for images, masks in dataset:\n",
    "        for i in range(num):\n",
    "            location = np.random.randint(width/2 - 1, 999 - width/2, (2,))\n",
    "            h, w = location[0], location[1]\n",
    "            d1 = int(width/2 - 1)\n",
    "            d2 = int(width - d1)\n",
    "            images_patch[j*num + i] = images[h-d1: h+d2, w-d1: w+d2, :]\n",
    "            masks_patch[j*num + i] = masks[h-d1: h+d2, w-d1: w+d2]\n",
    "        j = j + 1  \n",
    "    yield images_patch, masks_patch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = dataset_generator(dataset, 256, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 256, 256, 7) (700, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "for images_patch, masks_patch in dataset_generator:\n",
    "    print(images_patch.shape, masks_patch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(image_path, height, width, num):\n",
    "    image = get_raster(image_path)\n",
    "    if image.shape[-1] > 1:\n",
    "        image = norma_data(image, norma_methods='min-max')\n",
    "\n",
    "\n",
    "def random_sample(m):\n",
    "    x = np.random.randint(m/2 - 1, 999 - m/2)\n",
    "    y = np.random.randint(m/2 - 1, 999 - m/2)\n",
    "    location = (x, y)\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Treedatasets(object):\n",
    "    def __init__(self, image_path, mask_path, patch_size, number):\n",
    "        self.image_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.patch_size = patch_size\n",
    "        self.number = number\n",
    "        self.images = list(map(get_raster, image_path))\n",
    "        self.masks = list(map(get_raster, mask_path))\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_path) * self.number\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image_id = item // self.number\n",
    "        location = random_sample(self.patch_size)\n",
    "        image, mask = self.images[image_id], self.masks[image_id]\n",
    "        \n",
    "        h, w = location[0], location[1]\n",
    "        d1 = int(self.patch_size/2 - 1)\n",
    "        d2 = int(self.patch_size - d1)\n",
    "        \n",
    "        patch_image = image[h-d1: h+d2, w-d1: w+d2, :]\n",
    "        patch_mask = mask[h-d1: h+d2, w-d1: w+d2][:, :, 0]\n",
    "        \n",
    "        sample = {'image': patch_image, 'mask': patch_mask,\n",
    "                  'patch': location}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treedatasets = Treedatasets(image_path=images, mask_path=masks, patch_size=256, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample = Treedatasets[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(first_sample['mask'][:, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(first_sample['image'][:, :, 0:3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(x, nb_filters, strides):\n",
    "    res_path = BatchNormalization()(x)\n",
    "    res_path = Activation(activation='relu')(res_path)\n",
    "    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same', strides=strides[0])(res_path)\n",
    "    res_path = BatchNormalization()(res_path)\n",
    "    res_path = Activation(activation='relu')(res_path)\n",
    "    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same', strides=strides[1])(res_path)\n",
    "\n",
    "    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1), strides=strides[0])(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    res_path = add([shortcut, res_path])\n",
    "    return res_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    to_decoder = []\n",
    "\n",
    "    main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1))(x)\n",
    "    main_path = BatchNormalization()(main_path)\n",
    "    main_path = Activation(activation='relu')(main_path)\n",
    "\n",
    "    main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1))(main_path)\n",
    "\n",
    "    shortcut = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1))(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    main_path = add([shortcut, main_path])\n",
    "    # first branching to decoder\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    main_path = res_block(main_path, [128, 128], [(2, 2), (1, 1)])\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    main_path = res_block(main_path, [256, 256], [(2, 2), (1, 1)])\n",
    "    to_decoder.append(main_path)\n",
    "\n",
    "    return to_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x, from_encoder):\n",
    "    main_path = UpSampling2D(size=(2, 2))(x)\n",
    "    main_path = concatenate([main_path, from_encoder[2]], axis=3)\n",
    "    main_path = res_block(main_path, [256, 256], [(1, 1), (1, 1)])\n",
    "\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path)\n",
    "    main_path = concatenate([main_path, from_encoder[1]], axis=3)\n",
    "    main_path = res_block(main_path, [128, 128], [(1, 1), (1, 1)])\n",
    "\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path)\n",
    "    main_path = concatenate([main_path, from_encoder[0]], axis=3)\n",
    "    main_path = res_block(main_path, [64, 64], [(1, 1), (1, 1)])\n",
    "\n",
    "    return main_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_res_unet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    to_decoder = encoder(inputs)\n",
    "\n",
    "    path = res_block(to_decoder[2], [512, 512], [(2, 2), (1, 1)])\n",
    "\n",
    "    path = decoder(path, from_encoder=to_decoder)\n",
    "\n",
    "    path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (512, 512, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_res_unet(input_shape=input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer, Loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
